{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyabsa import ModelSaveOption, DeviceTypeOption\n",
    "from pyabsa import AspectPolarityClassification as APC\n",
    "config = APC.APCConfigManager.get_apc_config_english()\n",
    "config.num_epoch = 1\n",
    "config.model = APC.APCModelList.FAST_LSA_T_V2\n",
    "trainer = APC.APCTrainer(\n",
    "    config=config,\n",
    "    dataset='201.apa',\n",
    "    from_checkpoint=\"english\",\n",
    "    auto_device=DeviceTypeOption.AUTO,\n",
    "    checkpoint_save_mode=ModelSaveOption.SAVE_FULL_MODEL,\n",
    "    load_aug=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_set = set([\"Positive\", \"Negative\", \"Neutral\", \"Ambivalent\"])\n",
    "\n",
    "label_to_index = {\n",
    "    origin_label: int(idx)\n",
    "    for origin_label, idx in zip(sorted(label_set), range(len(label_set)))\n",
    "}\n",
    "index_to_label = {\n",
    "    int(idx): origin_label\n",
    "    for origin_label, idx in zip(sorted(label_set), range(len(label_set)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-26 17:53:04] (2.4.1.post1) Set Model Device: cpu\n",
      "[2024-08-26 17:53:04] (2.4.1.post1) Device Name: Unknown\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-08-26 17:53:09,266 INFO: PyABSA version: 2.4.1.post1\n",
      "2024-08-26 17:53:09,272 INFO: Transformers version: 4.24.0\n",
      "2024-08-26 17:53:09,274 INFO: Torch version: 2.0.1+cu117+cuda11.7\n",
      "2024-08-26 17:53:09,275 INFO: Device: Unknown\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-08-26 17:53:09,347 INFO: Searching dataset 202.apa_with_ambivalent in local disk\n",
      "2024-08-26 17:53:09,390 INFO: You can set load_aug=True in a trainer to augment your dataset (English only yet) and improve performance.\n",
      "2024-08-26 17:53:09,392 INFO: Please use a new folder to perform new text augment if the former augment in integrated_datasets/apc_datasets/202.apa_with_ambivalent errored unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/pool.py:268: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.Pool state=RUN pool_size=1>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/janwojtas/Msc/venv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at yangheng/deberta-v3-base-absa-v1.1 were not used when initializing DebertaV2Model: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 17:53:14,611 INFO: Load dataset from integrated_datasets/apc_datasets/202.apa_with_ambivalent/apa_with_ambivalent.train.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 4258/4258 [00:07<00:00, 596.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 17:53:21,771 INFO: Dataset Label Details: {'Negative': 628, 'Positive': 835, 'Neutral': 1659, 'Ambivalent': 771, 'Sum': 3893}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 17:53:24,217 INFO: train data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'Euro , the group announced on Thursday . BILD : SN/APA/THEMENBILD/HELMUT FOHRINGER CEO Strugl sees \\'completely unclear legal basis\\' for price adjustments \"In particular , wholesale and stock exchanges make very good results , the business with household customers is negative , \" said Strugl Michael , CEO of the Board of Management at a press conference on Thursday . The high wholesale prices from the second half of 2022 had been \"deferred and not fully expanded\"', 'text_spc': '[CLS] Euro , the group announced on Thursday . BILD : SN/APA/THEMENBILD/HELMUT FOHRINGER CEO Strugl sees \\'completely unclear legal basis\\' for price adjustments \"In particular , wholesale and stock exchanges make very good results , the business with household customers is negative , \" said Strugl Michael , CEO of the Board of Management at a press conference on Thursday . The high wholesale prices from the second half of 2022 had been \"deferred and not fully expanded\" [SEP] Strugl Michael [SEP]', 'aspect': 'Strugl Michael', 'aspect_position': tensor(0), 'lca_ids': tensor([0.2105, 0.2237, 0.2368, 0.2500, 0.2632, 0.2763, 0.2895, 0.3026, 0.3158,\n",
      "        0.3289, 0.3421, 0.3553, 0.3684, 0.3816, 0.3947, 0.4079, 0.4211, 0.4342,\n",
      "        0.4474, 0.4605, 0.4737, 0.4868, 0.5000, 0.5132, 0.5263, 0.5395, 0.5526,\n",
      "        0.5658, 0.5789, 0.5921, 0.6053, 0.6184, 0.6316, 0.6447, 0.6579, 0.6711,\n",
      "        0.6842, 0.6974, 0.7105, 0.7237, 0.7368, 0.7500, 0.7632, 0.7763, 0.7895,\n",
      "        0.8026, 0.8158, 0.8289, 0.8421, 0.8553, 0.8684, 0.8816, 0.8947, 0.9079,\n",
      "        0.9211, 0.9342, 0.9474, 0.9605, 0.9737, 0.9868, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9868, 0.9737, 0.9605,\n",
      "        0.9474, 0.9342, 0.9211, 0.9079, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.2105, 0.2237, 0.2368, 0.2500, 0.2632, 0.2763, 0.2895, 0.3026, 0.3158,\n",
      "        0.3289, 0.3421, 0.3553, 0.3684, 0.3816, 0.3947, 0.4079, 0.4211, 0.4342,\n",
      "        0.4474, 0.4605, 0.4737, 0.4868, 0.5000, 0.5132, 0.5263, 0.5395, 0.5526,\n",
      "        0.5658, 0.5789, 0.5921, 0.6053, 0.6184, 0.6316, 0.6447, 0.6579, 0.6711,\n",
      "        0.6842, 0.6974, 0.7105, 0.7237, 0.7368, 0.7500, 0.7632, 0.7763, 0.7895,\n",
      "        0.8026, 0.8158, 0.8289, 0.8421, 0.8553, 0.8684, 0.8816, 0.8947, 0.9079,\n",
      "        0.9211, 0.9342, 0.9474, 0.9605, 0.9737, 0.9868, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9868, 0.9737, 0.9605,\n",
      "        0.9474, 0.9342, 0.9211, 0.9079, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([    1,  7303,   366,   262,   596,  1577,   277,  1561,   323, 94857,\n",
      "          691,   877, 23776,   320, 50590,   320, 17102, 34555, 70860,   691,\n",
      "          320, 52484, 18718,  1193, 31606, 14242, 60508,  3033, 49664, 18309,\n",
      "         5649,   382, 44154,  8317,  1334,  1599,   280,   270,   710,  8594,\n",
      "          307,  2514,  1070,   366,  8691,   263,  1293,  9963,   365,   379,\n",
      "          397,   793,   366,   262,   460,   275,  3913,   887,   269,  2330,\n",
      "          366,   307,   357, 49664, 18309,  1841,   366,  3033,   265,   262,\n",
      "         1910,   265,  2024,   288,   266,  1924,  1957,   277,  1561,   323]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(2), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100,    2,    2,    2, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.2105, 0.2237, 0.2368, 0.2500, 0.2632, 0.2763, 0.2895, 0.3026, 0.3158,\n",
      "        0.3289, 0.3421, 0.3553, 0.3684, 0.3816, 0.3947, 0.4079, 0.4211, 0.4342,\n",
      "        0.4474, 0.4605, 0.4737, 0.4868, 0.5000, 0.5132, 0.5263, 0.5395, 0.5526,\n",
      "        0.5658, 0.5789, 0.5921, 0.6053, 0.6184, 0.6316, 0.6447, 0.6579, 0.6711,\n",
      "        0.6842, 0.6974, 0.7105, 0.7237, 0.7368, 0.7500, 0.7632, 0.7763, 0.7895,\n",
      "        0.8026, 0.8158, 0.8289, 0.8421, 0.8553, 0.8684, 0.8816, 0.8947, 0.9079,\n",
      "        0.9211, 0.9342, 0.9474, 0.9605, 0.9737, 0.9868, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9868, 0.9737, 0.9605,\n",
      "        0.9474, 0.9342, 0.9211, 0.9079, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([    1,  7303,   366,   262,   596,  1577,   277,  1561,   323, 94857,\n",
      "          691,   877, 23776,   320, 50590,   320, 17102, 34555, 70860,   691,\n",
      "          320, 52484, 18718,  1193, 31606, 14242, 60508,  3033, 49664, 18309,\n",
      "         5649,   382, 44154,  8317,  1334,  1599,   280,   270,   710,  8594,\n",
      "          307,  2514,  1070,   366,  8691,   263,  1293,  9963,   365,   379,\n",
      "          397,   793,   366,   262,   460,   275,  3913,   887,   269,  2330,\n",
      "          366,   307,   357, 49664, 18309,  1841,   366,  3033,   265,   262,\n",
      "         1910,   265,  2024,   288,   266,  1924,  1957,   277,  1561,   323]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.2105, 0.2237, 0.2368, 0.2500, 0.2632, 0.2763, 0.2895, 0.3026, 0.3158,\n",
      "        0.3289, 0.3421, 0.3553, 0.3684, 0.3816, 0.3947, 0.4079, 0.4211, 0.4342,\n",
      "        0.4474, 0.4605, 0.4737, 0.4868, 0.5000, 0.5132, 0.5263, 0.5395, 0.5526,\n",
      "        0.5658, 0.5789, 0.5921, 0.6053, 0.6184, 0.6316, 0.6447, 0.6579, 0.6711,\n",
      "        0.6842, 0.6974, 0.7105, 0.7237, 0.7368, 0.7500, 0.7632, 0.7763, 0.7895,\n",
      "        0.8026, 0.8158, 0.8289, 0.8421, 0.8553, 0.8684, 0.8816, 0.8947, 0.9079,\n",
      "        0.9211, 0.9342, 0.9474, 0.9605, 0.9737, 0.9868, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9868, 0.9737, 0.9605,\n",
      "        0.9474, 0.9342, 0.9211, 0.9079, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([    1,  7303,   366,   262,   596,  1577,   277,  1561,   323, 94857,\n",
      "          691,   877, 23776,   320, 50590,   320, 17102, 34555, 70860,   691,\n",
      "          320, 52484, 18718,  1193, 31606, 14242, 60508,  3033, 49664, 18309,\n",
      "         5649,   382, 44154,  8317,  1334,  1599,   280,   270,   710,  8594,\n",
      "          307,  2514,  1070,   366,  8691,   263,  1293,  9963,   365,   379,\n",
      "          397,   793,   366,   262,   460,   275,  3913,   887,   269,  2330,\n",
      "          366,   307,   357, 49664, 18309,  1841,   366,  3033,   265,   262,\n",
      "         1910,   265,  2024,   288,   266,  1924,  1957,   277,  1561,   323]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'Upper Austrian Economic Council Markus Achleitner (ÖVP) is the new institute “an apprenticeship from the crises” . A strong location in OÖ is important , as a large part of the manufacturing industry in Austria – for example at the Automotive location Steyr , where BMW Group International invests heavily in the E-Autoproduktion . For Achleitner , the focus of the presentation was therefore on the fact that the research knowledge is rapidly coming to the companies', 'text_spc': '[CLS] Upper Austrian Economic Council Markus Achleitner (ÖVP) is the new institute “an apprenticeship from the crises” . A strong location in OÖ is important , as a large part of the manufacturing industry in Austria – for example at the Automotive location Steyr , where BMW Group International invests heavily in the E-Autoproduktion . For Achleitner , the focus of the presentation was therefore on the fact that the research knowledge is rapidly coming to the companies [SEP] BMW Group International [SEP]', 'aspect': 'BMW Group International', 'aspect_position': tensor(0), 'lca_ids': tensor([0.3158, 0.3289, 0.3421, 0.3553, 0.3684, 0.3816, 0.3947, 0.4079, 0.4211,\n",
      "        0.4342, 0.4474, 0.4605, 0.4737, 0.4868, 0.5000, 0.5132, 0.5263, 0.5395,\n",
      "        0.5526, 0.5658, 0.5789, 0.5921, 0.6053, 0.6184, 0.6316, 0.6447, 0.6579,\n",
      "        0.6711, 0.6842, 0.6974, 0.7105, 0.7237, 0.7368, 0.7500, 0.7632, 0.7763,\n",
      "        0.7895, 0.8026, 0.8158, 0.8289, 0.8421, 0.8553, 0.8684, 0.8816, 0.8947,\n",
      "        0.9079, 0.9211, 0.9342, 0.9474, 0.9605, 0.9737, 0.9868, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9868, 0.9737,\n",
      "        0.9605, 0.9474, 0.9342, 0.9211, 0.9079, 0.8947, 0.8816, 0.8684, 0.8553,\n",
      "        0.8421, 0.8289, 0.8158, 0.8026, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.3158, 0.3289, 0.3421, 0.3553, 0.3684, 0.3816, 0.3947, 0.4079, 0.4211,\n",
      "        0.4342, 0.4474, 0.4605, 0.4737, 0.4868, 0.5000, 0.5132, 0.5263, 0.5395,\n",
      "        0.5526, 0.5658, 0.5789, 0.5921, 0.6053, 0.6184, 0.6316, 0.6447, 0.6579,\n",
      "        0.6711, 0.6842, 0.6974, 0.7105, 0.7237, 0.7368, 0.7500, 0.7632, 0.7763,\n",
      "        0.7895, 0.8026, 0.8158, 0.8289, 0.8421, 0.8553, 0.8684, 0.8816, 0.8947,\n",
      "        0.9079, 0.9211, 0.9342, 0.9474, 0.9605, 0.9737, 0.9868, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9868, 0.9737,\n",
      "        0.9605, 0.9474, 0.9342, 0.9211, 0.9079, 0.8947, 0.8816, 0.8684, 0.8553,\n",
      "        0.8421, 0.8289, 0.8158, 0.8026, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([    1,  9069, 14608,  5527,  1780, 35826, 33445, 26953, 21654,   287,\n",
      "        53138, 28362,   285,   269,   262,   353, 11791,   317,  1398, 24679,\n",
      "          292,   262, 17943,   318,   323,   336,   986,  1250,   267,  1130,\n",
      "        53138,   269,   539,   366,   283,   266,   614,   465,   265,   262,\n",
      "         3012,   769,   267,  9910,   377,   270,   738,   288,   262, 13946,\n",
      "         1250, 16641, 13094,   366,   399,  8327,  1543,  1282, 34979,  4605,\n",
      "          267,   262,   829,   271, 25943, 66173,  3359, 12582,   323,   434,\n",
      "        33445, 26953, 21654,   366,   262,  1087,   265,   262,  3011,   284]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(3), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100,    3,    3,    3, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.3158, 0.3289, 0.3421, 0.3553, 0.3684, 0.3816, 0.3947, 0.4079, 0.4211,\n",
      "        0.4342, 0.4474, 0.4605, 0.4737, 0.4868, 0.5000, 0.5132, 0.5263, 0.5395,\n",
      "        0.5526, 0.5658, 0.5789, 0.5921, 0.6053, 0.6184, 0.6316, 0.6447, 0.6579,\n",
      "        0.6711, 0.6842, 0.6974, 0.7105, 0.7237, 0.7368, 0.7500, 0.7632, 0.7763,\n",
      "        0.7895, 0.8026, 0.8158, 0.8289, 0.8421, 0.8553, 0.8684, 0.8816, 0.8947,\n",
      "        0.9079, 0.9211, 0.9342, 0.9474, 0.9605, 0.9737, 0.9868, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9868, 0.9737,\n",
      "        0.9605, 0.9474, 0.9342, 0.9211, 0.9079, 0.8947, 0.8816, 0.8684, 0.8553,\n",
      "        0.8421, 0.8289, 0.8158, 0.8026, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([    1,  9069, 14608,  5527,  1780, 35826, 33445, 26953, 21654,   287,\n",
      "        53138, 28362,   285,   269,   262,   353, 11791,   317,  1398, 24679,\n",
      "          292,   262, 17943,   318,   323,   336,   986,  1250,   267,  1130,\n",
      "        53138,   269,   539,   366,   283,   266,   614,   465,   265,   262,\n",
      "         3012,   769,   267,  9910,   377,   270,   738,   288,   262, 13946,\n",
      "         1250, 16641, 13094,   366,   399,  8327,  1543,  1282, 34979,  4605,\n",
      "          267,   262,   829,   271, 25943, 66173,  3359, 12582,   323,   434,\n",
      "        33445, 26953, 21654,   366,   262,  1087,   265,   262,  3011,   284]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.3158, 0.3289, 0.3421, 0.3553, 0.3684, 0.3816, 0.3947, 0.4079, 0.4211,\n",
      "        0.4342, 0.4474, 0.4605, 0.4737, 0.4868, 0.5000, 0.5132, 0.5263, 0.5395,\n",
      "        0.5526, 0.5658, 0.5789, 0.5921, 0.6053, 0.6184, 0.6316, 0.6447, 0.6579,\n",
      "        0.6711, 0.6842, 0.6974, 0.7105, 0.7237, 0.7368, 0.7500, 0.7632, 0.7763,\n",
      "        0.7895, 0.8026, 0.8158, 0.8289, 0.8421, 0.8553, 0.8684, 0.8816, 0.8947,\n",
      "        0.9079, 0.9211, 0.9342, 0.9474, 0.9605, 0.9737, 0.9868, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9868, 0.9737,\n",
      "        0.9605, 0.9474, 0.9342, 0.9211, 0.9079, 0.8947, 0.8816, 0.8684, 0.8553,\n",
      "        0.8421, 0.8289, 0.8158, 0.8026, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([    1,  9069, 14608,  5527,  1780, 35826, 33445, 26953, 21654,   287,\n",
      "        53138, 28362,   285,   269,   262,   353, 11791,   317,  1398, 24679,\n",
      "          292,   262, 17943,   318,   323,   336,   986,  1250,   267,  1130,\n",
      "        53138,   269,   539,   366,   283,   266,   614,   465,   265,   262,\n",
      "         3012,   769,   267,  9910,   377,   270,   738,   288,   262, 13946,\n",
      "         1250, 16641, 13094,   366,   399,  8327,  1543,  1282, 34979,  4605,\n",
      "          267,   262,   829,   271, 25943, 66173,  3359, 12582,   323,   434,\n",
      "        33445, 26953, 21654,   366,   262,  1087,   265,   262,  3011,   284]), 'right_dist': tensor(0)}]\n",
      "2024-08-26 17:53:26,165 INFO: Load dataset from integrated_datasets/apc_datasets/202.apa_with_ambivalent/apa_with_ambivalent.test.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 538/538 [00:01<00:00, 436.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 17:53:27,411 INFO: Dataset Label Details: {'Negative': 74, 'Positive': 104, 'Neutral': 222, 'Ambivalent': 95, 'Sum': 495}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 17:53:27,749 INFO: test data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'delivered a complete outrage with the demand for a \"full cost compensation\" . Who does not have a corresponding letter from a home doctor or specialist the health hotline can prove , according to Mayer Harald , all the costs incurred in a hospital-collection--which can go up to several thousand euros-for investigations and treatments themselves , and that without any flaming . \"Don\\'t come into question at all , \" said Minister of Health Johannes Rauch (Green)', 'text_spc': '[CLS] delivered a complete outrage with the demand for a \"full cost compensation\" . Who does not have a corresponding letter from a home doctor or specialist the health hotline can prove , according to Mayer Harald , all the costs incurred in a hospital-collection--which can go up to several thousand euros-for investigations and treatments themselves , and that without any flaming . \"Don\\'t come into question at all , \" said Minister of Health Johannes Rauch (Green) [SEP] Mayer Harald [SEP]', 'aspect': 'Mayer Harald', 'aspect_position': tensor(0), 'lca_ids': tensor([0.5584, 0.5714, 0.5844, 0.5974, 0.6104, 0.6234, 0.6364, 0.6494, 0.6623,\n",
      "        0.6753, 0.6883, 0.7013, 0.7143, 0.7273, 0.7403, 0.7532, 0.7662, 0.7792,\n",
      "        0.7922, 0.8052, 0.8182, 0.8312, 0.8442, 0.8571, 0.8701, 0.8831, 0.8961,\n",
      "        0.9091, 0.9221, 0.9351, 0.9481, 0.9610, 0.9740, 0.9870, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9870, 0.9740, 0.9610,\n",
      "        0.9481, 0.9351, 0.9221, 0.9091, 0.8961, 0.8831, 0.8701, 0.8571, 0.8442,\n",
      "        0.8312, 0.8182, 0.8052, 0.7922, 0.7792, 0.7662, 0.7532, 0.7403, 0.7273,\n",
      "        0.7143, 0.7013, 0.6883, 0.6753, 0.6623, 0.6494, 0.6364, 0.6234, 0.6104,\n",
      "        0.5974, 0.5844, 0.5714, 0.5584, 0.5455, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.5584, 0.5714, 0.5844, 0.5974, 0.6104, 0.6234, 0.6364, 0.6494, 0.6623,\n",
      "        0.6753, 0.6883, 0.7013, 0.7143, 0.7273, 0.7403, 0.7532, 0.7662, 0.7792,\n",
      "        0.7922, 0.8052, 0.8182, 0.8312, 0.8442, 0.8571, 0.8701, 0.8831, 0.8961,\n",
      "        0.9091, 0.9221, 0.9351, 0.9481, 0.9610, 0.9740, 0.9870, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9870, 0.9740, 0.9610,\n",
      "        0.9481, 0.9351, 0.9221, 0.9091, 0.8961, 0.8831, 0.8701, 0.8571, 0.8442,\n",
      "        0.8312, 0.8182, 0.8052, 0.7922, 0.7792, 0.7662, 0.7532, 0.7403, 0.7273,\n",
      "        0.7143, 0.7013, 0.6883, 0.6753, 0.6623, 0.6494, 0.6364, 0.6234, 0.6104,\n",
      "        0.5974, 0.5844, 0.5714, 0.5584, 0.5455, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([    1,  2621,   266,   850, 16796,   275,   262,  1935,   270,   266,\n",
      "          307, 11984,   751,  4327,   309,   323,  1876,   490,   298,   286,\n",
      "          266,  5786,  1837,   292,   266,   425,  2278,   289,  4104,   262,\n",
      "          622, 30546,   295,  3303,   366,   970,   264, 25486, 67396,   366,\n",
      "          305,   262,  1294, 12180,   267,   266,  2096,   271, 35434,   271,\n",
      "          271,  2637,   295,   424,   322,   264,   656,  4359, 12143,   271,\n",
      "         2102,  8039,   263,  4152,  1147,   366,   263,   272,   497,   356,\n",
      "        40177,   323,   307,  8705,   280,   297,   488,   352,   900,   288]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100,    1,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.5584, 0.5714, 0.5844, 0.5974, 0.6104, 0.6234, 0.6364, 0.6494, 0.6623,\n",
      "        0.6753, 0.6883, 0.7013, 0.7143, 0.7273, 0.7403, 0.7532, 0.7662, 0.7792,\n",
      "        0.7922, 0.8052, 0.8182, 0.8312, 0.8442, 0.8571, 0.8701, 0.8831, 0.8961,\n",
      "        0.9091, 0.9221, 0.9351, 0.9481, 0.9610, 0.9740, 0.9870, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9870, 0.9740, 0.9610,\n",
      "        0.9481, 0.9351, 0.9221, 0.9091, 0.8961, 0.8831, 0.8701, 0.8571, 0.8442,\n",
      "        0.8312, 0.8182, 0.8052, 0.7922, 0.7792, 0.7662, 0.7532, 0.7403, 0.7273,\n",
      "        0.7143, 0.7013, 0.6883, 0.6753, 0.6623, 0.6494, 0.6364, 0.6234, 0.6104,\n",
      "        0.5974, 0.5844, 0.5714, 0.5584, 0.5455, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([    1,  2621,   266,   850, 16796,   275,   262,  1935,   270,   266,\n",
      "          307, 11984,   751,  4327,   309,   323,  1876,   490,   298,   286,\n",
      "          266,  5786,  1837,   292,   266,   425,  2278,   289,  4104,   262,\n",
      "          622, 30546,   295,  3303,   366,   970,   264, 25486, 67396,   366,\n",
      "          305,   262,  1294, 12180,   267,   266,  2096,   271, 35434,   271,\n",
      "          271,  2637,   295,   424,   322,   264,   656,  4359, 12143,   271,\n",
      "         2102,  8039,   263,  4152,  1147,   366,   263,   272,   497,   356,\n",
      "        40177,   323,   307,  8705,   280,   297,   488,   352,   900,   288]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.5584, 0.5714, 0.5844, 0.5974, 0.6104, 0.6234, 0.6364, 0.6494, 0.6623,\n",
      "        0.6753, 0.6883, 0.7013, 0.7143, 0.7273, 0.7403, 0.7532, 0.7662, 0.7792,\n",
      "        0.7922, 0.8052, 0.8182, 0.8312, 0.8442, 0.8571, 0.8701, 0.8831, 0.8961,\n",
      "        0.9091, 0.9221, 0.9351, 0.9481, 0.9610, 0.9740, 0.9870, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9870, 0.9740, 0.9610,\n",
      "        0.9481, 0.9351, 0.9221, 0.9091, 0.8961, 0.8831, 0.8701, 0.8571, 0.8442,\n",
      "        0.8312, 0.8182, 0.8052, 0.7922, 0.7792, 0.7662, 0.7532, 0.7403, 0.7273,\n",
      "        0.7143, 0.7013, 0.6883, 0.6753, 0.6623, 0.6494, 0.6364, 0.6234, 0.6104,\n",
      "        0.5974, 0.5844, 0.5714, 0.5584, 0.5455, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([    1,  2621,   266,   850, 16796,   275,   262,  1935,   270,   266,\n",
      "          307, 11984,   751,  4327,   309,   323,  1876,   490,   298,   286,\n",
      "          266,  5786,  1837,   292,   266,   425,  2278,   289,  4104,   262,\n",
      "          622, 30546,   295,  3303,   366,   970,   264, 25486, 67396,   366,\n",
      "          305,   262,  1294, 12180,   267,   266,  2096,   271, 35434,   271,\n",
      "          271,  2637,   295,   424,   322,   264,   656,  4359, 12143,   271,\n",
      "         2102,  8039,   263,  4152,  1147,   366,   263,   272,   497,   356,\n",
      "        40177,   323,   307,  8705,   280,   297,   488,   352,   900,   288]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'by Köksal Baltaci The demand of medical chamber vice-president Mayer Harald after the return of an ambulance fee in hospitals is neither \"the expansion of American states\" in Austria nor \"a retro proposal whose failure is programmed\" . Barbara Teiber , Chairman of the Trade UnionGPA , the second of Andreas Huss , Vice-Chairman of the Austrian Health Insurance Fund ÖGK , was the first specialist diagnostic', 'text_spc': '[CLS] by Köksal Baltaci The demand of medical chamber vice-president Mayer Harald after the return of an ambulance fee in hospitals is neither \"the expansion of American states\" in Austria nor \"a retro proposal whose failure is programmed\" . Barbara Teiber , Chairman of the Trade UnionGPA , the second of Andreas Huss , Vice-Chairman of the Austrian Health Insurance Fund ÖGK , was the first specialist diagnostic [SEP] Mayer Harald [SEP]', 'aspect': 'Mayer Harald', 'aspect_position': tensor(0), 'lca_ids': tensor([0.8182, 0.8312, 0.8442, 0.8571, 0.8701, 0.8831, 0.8961, 0.9091, 0.9221,\n",
      "        0.9351, 0.9481, 0.9610, 0.9740, 0.9870, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9870, 0.9740, 0.9610, 0.9481, 0.9351,\n",
      "        0.9221, 0.9091, 0.8961, 0.8831, 0.8701, 0.8571, 0.8442, 0.8312, 0.8182,\n",
      "        0.8052, 0.7922, 0.7792, 0.7662, 0.7532, 0.7403, 0.7273, 0.7143, 0.7013,\n",
      "        0.6883, 0.6753, 0.6623, 0.6494, 0.6364, 0.6234, 0.6104, 0.5974, 0.5844,\n",
      "        0.5714, 0.5584, 0.5455, 0.5325, 0.5195, 0.5065, 0.4935, 0.4805, 0.4675,\n",
      "        0.4545, 0.4416, 0.4286, 0.4156, 0.4026, 0.3896, 0.3766, 0.3636, 0.3506,\n",
      "        0.3377, 0.3247, 0.3117, 0.2987, 0.2857, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.8182, 0.8312, 0.8442, 0.8571, 0.8701, 0.8831, 0.8961, 0.9091, 0.9221,\n",
      "        0.9351, 0.9481, 0.9610, 0.9740, 0.9870, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9870, 0.9740, 0.9610, 0.9481, 0.9351,\n",
      "        0.9221, 0.9091, 0.8961, 0.8831, 0.8701, 0.8571, 0.8442, 0.8312, 0.8182,\n",
      "        0.8052, 0.7922, 0.7792, 0.7662, 0.7532, 0.7403, 0.7273, 0.7143, 0.7013,\n",
      "        0.6883, 0.6753, 0.6623, 0.6494, 0.6364, 0.6234, 0.6104, 0.5974, 0.5844,\n",
      "        0.5714, 0.5584, 0.5455, 0.5325, 0.5195, 0.5065, 0.4935, 0.4805, 0.4675,\n",
      "        0.4545, 0.4416, 0.4286, 0.4156, 0.4026, 0.3896, 0.3766, 0.3636, 0.3506,\n",
      "        0.3377, 0.3247, 0.3117, 0.2987, 0.2857, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([    1,   293, 58842,  1165,   268,  1544, 11396,   297, 36908,   279,\n",
      "         1935,   265,  1159,  7011,  4624,   271, 20852, 25486, 67396,   385,\n",
      "          262,  1067,   265,   299, 14395,  2383,   267,  5747,   269,  3899,\n",
      "          307,   724,  3850,   265,   733,  1603,   309,   267,  9910,  2498,\n",
      "          307,   452, 10392,  3803,  1661,  2694,   269, 16270,   309,   323,\n",
      "         7572, 10142, 38762,   366,  6170,   265,   262,  4707,  2432, 86693,\n",
      "          366,   262,   567,   265, 22473, 53940,   366,  5301,   271, 63965,\n",
      "          265,   262, 14608,  1516,  3905,  4251, 35959, 71493,   366,   284]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100,    1,    1, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.8182, 0.8312, 0.8442, 0.8571, 0.8701, 0.8831, 0.8961, 0.9091, 0.9221,\n",
      "        0.9351, 0.9481, 0.9610, 0.9740, 0.9870, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9870, 0.9740, 0.9610, 0.9481, 0.9351,\n",
      "        0.9221, 0.9091, 0.8961, 0.8831, 0.8701, 0.8571, 0.8442, 0.8312, 0.8182,\n",
      "        0.8052, 0.7922, 0.7792, 0.7662, 0.7532, 0.7403, 0.7273, 0.7143, 0.7013,\n",
      "        0.6883, 0.6753, 0.6623, 0.6494, 0.6364, 0.6234, 0.6104, 0.5974, 0.5844,\n",
      "        0.5714, 0.5584, 0.5455, 0.5325, 0.5195, 0.5065, 0.4935, 0.4805, 0.4675,\n",
      "        0.4545, 0.4416, 0.4286, 0.4156, 0.4026, 0.3896, 0.3766, 0.3636, 0.3506,\n",
      "        0.3377, 0.3247, 0.3117, 0.2987, 0.2857, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([    1,   293, 58842,  1165,   268,  1544, 11396,   297, 36908,   279,\n",
      "         1935,   265,  1159,  7011,  4624,   271, 20852, 25486, 67396,   385,\n",
      "          262,  1067,   265,   299, 14395,  2383,   267,  5747,   269,  3899,\n",
      "          307,   724,  3850,   265,   733,  1603,   309,   267,  9910,  2498,\n",
      "          307,   452, 10392,  3803,  1661,  2694,   269, 16270,   309,   323,\n",
      "         7572, 10142, 38762,   366,  6170,   265,   262,  4707,  2432, 86693,\n",
      "          366,   262,   567,   265, 22473, 53940,   366,  5301,   271, 63965,\n",
      "          265,   262, 14608,  1516,  3905,  4251, 35959, 71493,   366,   284]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.8182, 0.8312, 0.8442, 0.8571, 0.8701, 0.8831, 0.8961, 0.9091, 0.9221,\n",
      "        0.9351, 0.9481, 0.9610, 0.9740, 0.9870, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9870, 0.9740, 0.9610, 0.9481, 0.9351,\n",
      "        0.9221, 0.9091, 0.8961, 0.8831, 0.8701, 0.8571, 0.8442, 0.8312, 0.8182,\n",
      "        0.8052, 0.7922, 0.7792, 0.7662, 0.7532, 0.7403, 0.7273, 0.7143, 0.7013,\n",
      "        0.6883, 0.6753, 0.6623, 0.6494, 0.6364, 0.6234, 0.6104, 0.5974, 0.5844,\n",
      "        0.5714, 0.5584, 0.5455, 0.5325, 0.5195, 0.5065, 0.4935, 0.4805, 0.4675,\n",
      "        0.4545, 0.4416, 0.4286, 0.4156, 0.4026, 0.3896, 0.3766, 0.3636, 0.3506,\n",
      "        0.3377, 0.3247, 0.3117, 0.2987, 0.2857, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([    1,   293, 58842,  1165,   268,  1544, 11396,   297, 36908,   279,\n",
      "         1935,   265,  1159,  7011,  4624,   271, 20852, 25486, 67396,   385,\n",
      "          262,  1067,   265,   299, 14395,  2383,   267,  5747,   269,  3899,\n",
      "          307,   724,  3850,   265,   733,  1603,   309,   267,  9910,  2498,\n",
      "          307,   452, 10392,  3803,  1661,  2694,   269, 16270,   309,   323,\n",
      "         7572, 10142, 38762,   366,  6170,   265,   262,  4707,  2432, 86693,\n",
      "          366,   262,   567,   265, 22473, 53940,   366,  5301,   271, 63965,\n",
      "          265,   262, 14608,  1516,  3905,  4251, 35959, 71493,   366,   284]), 'right_dist': tensor(0)}]\n",
      "2024-08-26 17:53:28,573 INFO: Load dataset from integrated_datasets/apc_datasets/202.apa_with_ambivalent/apa_with_ambivalent.valid.dat.apc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preparing dataloader: 100%|██████████| 544/544 [00:01<00:00, 418.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 17:53:29,903 INFO: Dataset Label Details: {'Negative': 77, 'Positive': 107, 'Neutral': 230, 'Ambivalent': 80, 'Sum': 494}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-26 17:53:30,222 INFO: valid data examples:\n",
      " [{'ex_id': tensor(0), 'text_raw': 'At the Europäisches Forum Alpbach (EFA) , around 120 members of the Fridays For Future movement demonstrated on Friday . The young people did not agree with the financiers of the forum : The conference will be financed by banks that are heavily involved in fossil energy', 'text_spc': '[CLS] At the Europäisches Forum Alpbach (EFA) , around 120 members of the Fridays For Future movement demonstrated on Friday . The young people did not agree with the financiers of the forum : The conference will be financed by banks that are heavily involved in fossil energy [SEP] Europäisches Forum Alpbach [SEP]', 'aspect': 'Europäisches Forum Alpbach', 'aspect_position': tensor(0), 'lca_ids': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9818, 0.9636, 0.9455, 0.9273, 0.9091,\n",
      "        0.8909, 0.8727, 0.8545, 0.8364, 0.8182, 0.8000, 0.7818, 0.7636, 0.7455,\n",
      "        0.7273, 0.7091, 0.6909, 0.6727, 0.6545, 0.6364, 0.6182, 0.6000, 0.5818,\n",
      "        0.5636, 0.5455, 0.5273, 0.5091, 0.4909, 0.4727, 0.4545, 0.4364, 0.4182,\n",
      "        0.4000, 0.3818, 0.3636, 0.3455, 0.3273, 0.3091, 0.2909, 0.2727, 0.2545,\n",
      "        0.2364, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9818, 0.9636, 0.9455, 0.9273, 0.9091,\n",
      "        0.8909, 0.8727, 0.8545, 0.8364, 0.8182, 0.8000, 0.7818, 0.7636, 0.7455,\n",
      "        0.7273, 0.7091, 0.6909, 0.6727, 0.6545, 0.6364, 0.6182, 0.6000, 0.5818,\n",
      "        0.5636, 0.5455, 0.5273, 0.5091, 0.4909, 0.4727, 0.4545, 0.4364, 0.4182,\n",
      "        0.4000, 0.3818, 0.3636, 0.3455, 0.3273, 0.3091, 0.2909, 0.2727, 0.2545,\n",
      "        0.2364, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([    1,   620,   262,  7303, 80428, 20841,   268,  5812, 49359, 15305,\n",
      "          287, 94395,   285,   366,   441,  4811,   742,   265,   262, 26859,\n",
      "          434,  6230,  1807,  5295,   277,  1178,   323,   279,   856,   355,\n",
      "          464,   298,  1757,   275,   262, 54913,   265,   262,  3867,   877,\n",
      "          279,  1957,   296,   282, 20995,   293,  3314,   272,   281,  4605,\n",
      "         1190,   267, 10239,   843,     2,  7303, 80428, 20841,   268,  5812,\n",
      "        49359, 15305,     2,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100,    1,    1,    1,    1,    1,    1,    1, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9818, 0.9636, 0.9455, 0.9273, 0.9091,\n",
      "        0.8909, 0.8727, 0.8545, 0.8364, 0.8182, 0.8000, 0.7818, 0.7636, 0.7455,\n",
      "        0.7273, 0.7091, 0.6909, 0.6727, 0.6545, 0.6364, 0.6182, 0.6000, 0.5818,\n",
      "        0.5636, 0.5455, 0.5273, 0.5091, 0.4909, 0.4727, 0.4545, 0.4364, 0.4182,\n",
      "        0.4000, 0.3818, 0.3636, 0.3455, 0.3273, 0.3091, 0.2909, 0.2727, 0.2545,\n",
      "        0.2364, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([    1,   620,   262,  7303, 80428, 20841,   268,  5812, 49359, 15305,\n",
      "          287, 94395,   285,   366,   441,  4811,   742,   265,   262, 26859,\n",
      "          434,  6230,  1807,  5295,   277,  1178,   323,   279,   856,   355,\n",
      "          464,   298,  1757,   275,   262, 54913,   265,   262,  3867,   877,\n",
      "          279,  1957,   296,   282, 20995,   293,  3314,   272,   281,  4605,\n",
      "         1190,   267, 10239,   843,     2,  7303, 80428, 20841,   268,  5812,\n",
      "        49359, 15305,     2,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.9818, 0.9636, 0.9455, 0.9273, 0.9091,\n",
      "        0.8909, 0.8727, 0.8545, 0.8364, 0.8182, 0.8000, 0.7818, 0.7636, 0.7455,\n",
      "        0.7273, 0.7091, 0.6909, 0.6727, 0.6545, 0.6364, 0.6182, 0.6000, 0.5818,\n",
      "        0.5636, 0.5455, 0.5273, 0.5091, 0.4909, 0.4727, 0.4545, 0.4364, 0.4182,\n",
      "        0.4000, 0.3818, 0.3636, 0.3455, 0.3273, 0.3091, 0.2909, 0.2727, 0.2545,\n",
      "        0.2364, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([    1,   620,   262,  7303, 80428, 20841,   268,  5812, 49359, 15305,\n",
      "          287, 94395,   285,   366,   441,  4811,   742,   265,   262, 26859,\n",
      "          434,  6230,  1807,  5295,   277,  1178,   323,   279,   856,   355,\n",
      "          464,   298,  1757,   275,   262, 54913,   265,   262,  3867,   877,\n",
      "          279,  1957,   296,   282, 20995,   293,  3314,   272,   281,  4605,\n",
      "         1190,   267, 10239,   843,     2,  7303, 80428, 20841,   268,  5812,\n",
      "        49359, 15305,     2,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'right_dist': tensor(0)}, {'ex_id': tensor(1), 'text_raw': 'In 2022 , sales already had a strong effect . Does an internal combustion engine , which provides electricity for almost any range , now deliver the decisive argument ? BMW Group International made other experiences : The electric car i3 was left with optional range extender(a moped two-cylinder from Kymco) and soon removed from the program . If electric , all electric', 'text_spc': '[CLS] In 2022 , sales already had a strong effect . Does an internal combustion engine , which provides electricity for almost any range , now deliver the decisive argument ? BMW Group International made other experiences : The electric car i3 was left with optional range extender(a moped two-cylinder from Kymco) and soon removed from the program . If electric , all electric [SEP] BMW Group International [SEP]', 'aspect': 'BMW Group International', 'aspect_position': tensor(0), 'lca_ids': tensor([0.6111, 0.6250, 0.6389, 0.6528, 0.6667, 0.6806, 0.6944, 0.7083, 0.7222,\n",
      "        0.7361, 0.7500, 0.7639, 0.7778, 0.7917, 0.8056, 0.8194, 0.8333, 0.8472,\n",
      "        0.8611, 0.8750, 0.8889, 0.9028, 0.9167, 0.9306, 0.9444, 0.9583, 0.9722,\n",
      "        0.9861, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9861, 0.9722, 0.9583, 0.9444, 0.9306, 0.9167, 0.9028, 0.8889,\n",
      "        0.8750, 0.8611, 0.8472, 0.8333, 0.8194, 0.8056, 0.7917, 0.7778, 0.7639,\n",
      "        0.7500, 0.7361, 0.7222, 0.7083, 0.6944, 0.6806, 0.6667, 0.6528, 0.6389,\n",
      "        0.6250, 0.6111, 0.5972, 0.5833, 0.5694, 0.5556, 0.5417, 0.5278, 0.5139,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_vec': tensor(0), 'lcf_cdw_vec': tensor([0.6111, 0.6250, 0.6389, 0.6528, 0.6667, 0.6806, 0.6944, 0.7083, 0.7222,\n",
      "        0.7361, 0.7500, 0.7639, 0.7778, 0.7917, 0.8056, 0.8194, 0.8333, 0.8472,\n",
      "        0.8611, 0.8750, 0.8889, 0.9028, 0.9167, 0.9306, 0.9444, 0.9583, 0.9722,\n",
      "        0.9861, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9861, 0.9722, 0.9583, 0.9444, 0.9306, 0.9167, 0.9028, 0.8889,\n",
      "        0.8750, 0.8611, 0.8472, 0.8333, 0.8194, 0.8056, 0.7917, 0.7778, 0.7639,\n",
      "        0.7500, 0.7361, 0.7222, 0.7083, 0.6944, 0.6806, 0.6667, 0.6528, 0.6389,\n",
      "        0.6250, 0.6111, 0.5972, 0.5833, 0.5694, 0.5556, 0.5417, 0.5278, 0.5139,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'lcfs_vec': tensor(0), 'lcfs_cdw_vec': tensor(0), 'lcfs_cdm_vec': tensor(0), 'dlcf_vec': tensor(0), 'dlcfs_vec': tensor(0), 'depend_vec': tensor(0), 'depended_vec': tensor(0), 'spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'text_indices': tensor([    1,   344, 18114,   366,  1160,   637,   330,   266,   986,  1290,\n",
      "          323,  2467,   299,  2508, 17974,  1868,   366,   319,   888,  4027,\n",
      "          270,   823,   356,   778,   366,   394,  2074,   262, 16049,  3585,\n",
      "         1102,  8327,  1543,  1282,   412,   340,  2056,   877,   279,  2828,\n",
      "          640,   584,   508,   284,   595,   275,  6862,   778, 41325,   555,\n",
      "          452, 64372,   375,   271, 26235,   292, 70008,  1902,   285,   263,\n",
      "          950,  2421,   292,   262,   655,   323,   369,  2828,   366,   305,\n",
      "         2828,     2,  8327,  1543,  1282,     2,     0,     0,     0,     0]), 'aspect_bert_indices': tensor(0), 'text_raw_bert_indices': tensor(0), 'polarity': tensor(1), 'cluster_ids': tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100,    1,    1,    1, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100]), 'side_ex_ids': tensor(0), 'left_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'left_lcf_cdw_vec': tensor([0.6111, 0.6250, 0.6389, 0.6528, 0.6667, 0.6806, 0.6944, 0.7083, 0.7222,\n",
      "        0.7361, 0.7500, 0.7639, 0.7778, 0.7917, 0.8056, 0.8194, 0.8333, 0.8472,\n",
      "        0.8611, 0.8750, 0.8889, 0.9028, 0.9167, 0.9306, 0.9444, 0.9583, 0.9722,\n",
      "        0.9861, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9861, 0.9722, 0.9583, 0.9444, 0.9306, 0.9167, 0.9028, 0.8889,\n",
      "        0.8750, 0.8611, 0.8472, 0.8333, 0.8194, 0.8056, 0.7917, 0.7778, 0.7639,\n",
      "        0.7500, 0.7361, 0.7222, 0.7083, 0.6944, 0.6806, 0.6667, 0.6528, 0.6389,\n",
      "        0.6250, 0.6111, 0.5972, 0.5833, 0.5694, 0.5556, 0.5417, 0.5278, 0.5139,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'left_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'left_text_indices': tensor([    1,   344, 18114,   366,  1160,   637,   330,   266,   986,  1290,\n",
      "          323,  2467,   299,  2508, 17974,  1868,   366,   319,   888,  4027,\n",
      "          270,   823,   356,   778,   366,   394,  2074,   262, 16049,  3585,\n",
      "         1102,  8327,  1543,  1282,   412,   340,  2056,   877,   279,  2828,\n",
      "          640,   584,   508,   284,   595,   275,  6862,   778, 41325,   555,\n",
      "          452, 64372,   375,   271, 26235,   292, 70008,  1902,   285,   263,\n",
      "          950,  2421,   292,   262,   655,   323,   369,  2828,   366,   305,\n",
      "         2828,     2,  8327,  1543,  1282,     2,     0,     0,     0,     0]), 'left_dist': tensor(0), 'right_lcf_cdm_vec': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'right_lcf_cdw_vec': tensor([0.6111, 0.6250, 0.6389, 0.6528, 0.6667, 0.6806, 0.6944, 0.7083, 0.7222,\n",
      "        0.7361, 0.7500, 0.7639, 0.7778, 0.7917, 0.8056, 0.8194, 0.8333, 0.8472,\n",
      "        0.8611, 0.8750, 0.8889, 0.9028, 0.9167, 0.9306, 0.9444, 0.9583, 0.9722,\n",
      "        0.9861, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 0.9861, 0.9722, 0.9583, 0.9444, 0.9306, 0.9167, 0.9028, 0.8889,\n",
      "        0.8750, 0.8611, 0.8472, 0.8333, 0.8194, 0.8056, 0.7917, 0.7778, 0.7639,\n",
      "        0.7500, 0.7361, 0.7222, 0.7083, 0.6944, 0.6806, 0.6667, 0.6528, 0.6389,\n",
      "        0.6250, 0.6111, 0.5972, 0.5833, 0.5694, 0.5556, 0.5417, 0.5278, 0.5139,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]), 'right_spc_mask_vec': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1.]), 'right_text_indices': tensor([    1,   344, 18114,   366,  1160,   637,   330,   266,   986,  1290,\n",
      "          323,  2467,   299,  2508, 17974,  1868,   366,   319,   888,  4027,\n",
      "          270,   823,   356,   778,   366,   394,  2074,   262, 16049,  3585,\n",
      "         1102,  8327,  1543,  1282,   412,   340,  2056,   877,   279,  2828,\n",
      "          640,   584,   508,   284,   595,   275,  6862,   778, 41325,   555,\n",
      "          452, 64372,   375,   271, 26235,   292, 70008,  1902,   285,   263,\n",
      "          950,  2421,   292,   262,   655,   323,   369,  2828,   366,   305,\n",
      "         2828,     2,  8327,  1543,  1282,     2,     0,     0,     0,     0]), 'right_dist': tensor(0)}]\n",
      "[2024-08-26 17:53:30] (2.4.1.post1) \u001b[31mCaching dataset... please remove cached dataset if any problem happens.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m config\u001b[38;5;241m.\u001b[39mlabel_to_index \u001b[38;5;241m=\u001b[39m label_to_index\n",
      "\u001b[1;32m      8\u001b[0m config\u001b[38;5;241m.\u001b[39mindex_to_label \u001b[38;5;241m=\u001b[39m index_to_label\n",
      "\u001b[0;32m----> 9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mAPC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPCTrainer\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m202.apa_with_ambivalent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDeviceTypeOption\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTO\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_save_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelSaveOption\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSAVE_FULL_MODEL\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_aug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/pyabsa/tasks/AspectPolarityClassification/trainer/apc_trainer.py:69\u001b[0m, in \u001b[0;36mAPCTrainer.__init__\u001b[0;34m(self, config, dataset, from_checkpoint, checkpoint_save_mode, auto_device, path_to_save, load_aug)\u001b[0m\n",
      "\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtask_code \u001b[38;5;241m=\u001b[39m TaskCodeOption\u001b[38;5;241m.\u001b[39mAspect_Polarity_Classification\n",
      "\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m=\u001b[39m TaskNameOption()\u001b[38;5;241m.\u001b[39mget(\n",
      "\u001b[1;32m     66\u001b[0m     TaskCodeOption\u001b[38;5;241m.\u001b[39mAspect_Polarity_Classification\n",
      "\u001b[1;32m     67\u001b[0m )\n",
      "\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/pyabsa/framework/trainer_class/trainer_template.py:240\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m s\n",
      "\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mcheckpoint_save_mode:\n",
      "\u001b[0;32m--> 240\u001b[0m     model_path\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_instructor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrun())\n",
      "\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# always return the last trained model if you don't save trained model\u001b[39;00m\n",
      "\u001b[1;32m    243\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_model_class(\n",
      "\u001b[1;32m    244\u001b[0m         checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_instructor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\u001b[38;5;241m.\u001b[39mrun()\n",
      "\u001b[1;32m    245\u001b[0m     )\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/pyabsa/tasks/AspectPolarityClassification/instructor/apc_instructor.py:42\u001b[0m, in \u001b[0;36mAPCTrainingInstructor.__init__\u001b[0;34m(self, config)\u001b[0m\n",
      "\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n",
      "\u001b[1;32m     40\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n",
      "\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_dataset_and_prepare_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_misc()\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/pyabsa/tasks/AspectPolarityClassification/instructor/apc_instructor.py:30\u001b[0m, in \u001b[0;36mAPCTrainingInstructor._load_dataset_and_prepare_dataloader\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_dataset_and_prepare_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAPCEnsembler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtokenizer\n",
      "\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_set\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/pyabsa/tasks/AspectPolarityClassification/instructor/ensembler.py:276\u001b[0m, in \u001b[0;36mAPCEnsembler.__init__\u001b[0;34m(self, config, load_dataset, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    269\u001b[0m     fprint(\n",
      "\u001b[1;32m    270\u001b[0m         colored(\n",
      "\u001b[1;32m    271\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaching dataset... please remove cached dataset if any problem happens.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    272\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m    273\u001b[0m         )\n",
      "\u001b[1;32m    274\u001b[0m     )\n",
      "\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(cache_path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_cache:\n",
      "\u001b[0;32m--> 276\u001b[0m         \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf_cache\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_dataset:\n",
      "\u001b[1;32m    282\u001b[0m     train_sampler \u001b[38;5;241m=\u001b[39m RandomSampler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set)\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/torch/storage.py:770\u001b[0m, in \u001b[0;36mTypedStorage.__reduce__\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__reduce__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;32m    769\u001b[0m     b \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n",
      "\u001b[0;32m--> 770\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_use_new_zipfile_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_load_from_bytes, (b\u001b[38;5;241m.\u001b[39mgetvalue(),))\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n",
      "\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n",
      "\u001b[0;32m--> 445\u001b[0m         \u001b[43m_legacy_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/torch/serialization.py:582\u001b[0m, in \u001b[0;36m_legacy_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n",
      "\u001b[1;32m    580\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(f, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n",
      "\u001b[1;32m    581\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n",
      "\u001b[0;32m--> 582\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    584\u001b[0m serialized_storage_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(serialized_storages\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;32m    585\u001b[0m pickle_module\u001b[38;5;241m.\u001b[39mdump(serialized_storage_keys, f, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/torch/serialization.py:519\u001b[0m, in \u001b[0;36m_legacy_save.<locals>.persistent_id\u001b[0;34m(obj)\u001b[0m\n",
      "\u001b[1;32m    517\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;32m    518\u001b[0m storage_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(storage\u001b[38;5;241m.\u001b[39m_cdata)\n",
      "\u001b[0;32m--> 519\u001b[0m location \u001b[38;5;241m=\u001b[39m \u001b[43mlocation_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# TODO: There's an issue here with FC. It might be impossible to\u001b[39;00m\n",
      "\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# solve, but it's worth noting. Imagine we save a list `[storage,\u001b[39;00m\n",
      "\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# tensor]`, where `tensor.storage()` is the same as `storage`, and\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# just tensors, as long as all views share the same dtype as the\u001b[39;00m\n",
      "\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# tensor they are viewing.\u001b[39;00m\n",
      "\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m serialized_storages:\n",
      "\n",
      "File \u001b[0;32m~/Msc/venv/lib/python3.10/site-packages/torch/serialization.py:208\u001b[0m, in \u001b[0;36mlocation_tag\u001b[0;34m(storage)\u001b[0m\n",
      "\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlocation_tag\u001b[39m(storage: Union[Storage, torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage, torch\u001b[38;5;241m.\u001b[39mUntypedStorage]):\n",
      "\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, tagger, _ \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n",
      "\u001b[0;32m--> 208\u001b[0m         location \u001b[38;5;241m=\u001b[39m \u001b[43mtagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    209\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m location:\n",
      "\u001b[1;32m    210\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m location\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyabsa import ModelSaveOption, DeviceTypeOption\n",
    "from pyabsa import AspectPolarityClassification as APC\n",
    "config = APC.APCConfigManager.get_apc_config_english()\n",
    "config.num_epoch = 1\n",
    "config.model = APC.APCModelList.FAST_LSA_T_V2\n",
    "config.output_dim = 4\n",
    "config.label_to_index = label_to_index\n",
    "config.index_to_label = index_to_label\n",
    "trainer = APC.APCTrainer(\n",
    "    config=config,\n",
    "    dataset='202.apa_with_ambivalent',\n",
    "    from_checkpoint=\"english\",\n",
    "    auto_device=DeviceTypeOption.AUTO,\n",
    "    checkpoint_save_mode=ModelSaveOption.SAVE_FULL_MODEL,\n",
    "    load_aug=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        lines = infile.readlines()\n",
    "        \n",
    "        for i in range(0, len(lines), 3):\n",
    "            if i + 2 >= len(lines):\n",
    "                break\n",
    "            sentence = lines[i].strip()\n",
    "            aspect = lines[i+1].strip()\n",
    "            sentiment = lines[i+2].strip()\n",
    "            sentence = sentence.replace(\"$T$\", f'[B-ASP]{aspect}[E-ASP]')\n",
    "            number_of_aspect_tokens = sentence.count('[B-ASP]')\n",
    "            \n",
    "            processed_sentence = f\"{sentence} $LABEL$\" + f\" {sentiment},\" * number_of_aspect_tokens\n",
    "            processed_sentence = processed_sentence[:-1]\n",
    "            outfile.write(processed_sentence + \"\\n\")\n",
    "\n",
    "\n",
    "input_file = './integrated_datasets/apc_datasets/201.apa_full/apa.test.dat.apc'\n",
    "output_file = './integrated_datasets/apc_datasets/201.apa_full/apa.test.dat.apc.inference'\n",
    "process_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "with open(input_file, 'r') as infile:\n",
    "    lines = infile.readlines()\n",
    "    for i in range(0, len(lines), 3):\n",
    "        sentiments.append(lines[i+2].strip())\n",
    "\n",
    "# summarize the sentiment distribution\n",
    "from collections import Counter\n",
    "counter = Counter(sentiments)\n",
    "\n",
    "print(counter)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
