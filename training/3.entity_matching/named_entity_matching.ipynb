{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.utils import embedding_functions\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>end_pos</th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a5164fe0-f670-4168-9ca8-3ce023d42fed</td>\n",
       "      <td>483</td>\n",
       "      <td>516</td>\n",
       "      <td>Upper Austrian Chamber of Doctors</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.864500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a5164fe0-f670-4168-9ca8-3ce023d42fed</td>\n",
       "      <td>605</td>\n",
       "      <td>608</td>\n",
       "      <td>OÖN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a5164fe0-f670-4168-9ca8-3ce023d42fed</td>\n",
       "      <td>828</td>\n",
       "      <td>863</td>\n",
       "      <td>Wolfgang Ziegler,Kurienobmann-Stell</td>\n",
       "      <td>PER</td>\n",
       "      <td>0.979083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a5164fe0-f670-4168-9ca8-3ce023d42fed</td>\n",
       "      <td>913</td>\n",
       "      <td>935</td>\n",
       "      <td>OÖ Medical Association</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.945547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a5164fe0-f670-4168-9ca8-3ce023d42fed</td>\n",
       "      <td>1170</td>\n",
       "      <td>1189</td>\n",
       "      <td>mayorChristian Graf</td>\n",
       "      <td>PER</td>\n",
       "      <td>0.859976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32964</th>\n",
       "      <td>8e6c9db9-8ca1-421d-9923-c3ff77243ce1</td>\n",
       "      <td>2105</td>\n",
       "      <td>2136</td>\n",
       "      <td>House of Digitization Hergovich</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.981821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32965</th>\n",
       "      <td>8e6c9db9-8ca1-421d-9923-c3ff77243ce1</td>\n",
       "      <td>2699</td>\n",
       "      <td>2708</td>\n",
       "      <td>Hergovich</td>\n",
       "      <td>PER</td>\n",
       "      <td>0.999710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32966</th>\n",
       "      <td>8e6c9db9-8ca1-421d-9923-c3ff77243ce1</td>\n",
       "      <td>2719</td>\n",
       "      <td>2723</td>\n",
       "      <td>SSPÖ</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.988402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32967</th>\n",
       "      <td>8e6c9db9-8ca1-421d-9923-c3ff77243ce1</td>\n",
       "      <td>2891</td>\n",
       "      <td>2894</td>\n",
       "      <td>ÖVP</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.999398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32968</th>\n",
       "      <td>8e6c9db9-8ca1-421d-9923-c3ff77243ce1</td>\n",
       "      <td>3195</td>\n",
       "      <td>3216</td>\n",
       "      <td>House of Digitization</td>\n",
       "      <td>ORG</td>\n",
       "      <td>0.986370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32969 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 article_id  start_pos  end_pos  \\\n",
       "0      a5164fe0-f670-4168-9ca8-3ce023d42fed        483      516   \n",
       "1      a5164fe0-f670-4168-9ca8-3ce023d42fed        605      608   \n",
       "2      a5164fe0-f670-4168-9ca8-3ce023d42fed        828      863   \n",
       "3      a5164fe0-f670-4168-9ca8-3ce023d42fed        913      935   \n",
       "4      a5164fe0-f670-4168-9ca8-3ce023d42fed       1170     1189   \n",
       "...                                     ...        ...      ...   \n",
       "32964  8e6c9db9-8ca1-421d-9923-c3ff77243ce1       2105     2136   \n",
       "32965  8e6c9db9-8ca1-421d-9923-c3ff77243ce1       2699     2708   \n",
       "32966  8e6c9db9-8ca1-421d-9923-c3ff77243ce1       2719     2723   \n",
       "32967  8e6c9db9-8ca1-421d-9923-c3ff77243ce1       2891     2894   \n",
       "32968  8e6c9db9-8ca1-421d-9923-c3ff77243ce1       3195     3216   \n",
       "\n",
       "                                      name label  confidence  \n",
       "0        Upper Austrian Chamber of Doctors   ORG    0.864500  \n",
       "1                                      OÖN   ORG    0.999800  \n",
       "2      Wolfgang Ziegler,Kurienobmann-Stell   PER    0.979083  \n",
       "3                   OÖ Medical Association   ORG    0.945547  \n",
       "4                      mayorChristian Graf   PER    0.859976  \n",
       "...                                    ...   ...         ...  \n",
       "32964      House of Digitization Hergovich   ORG    0.981821  \n",
       "32965                            Hergovich   PER    0.999710  \n",
       "32966                                 SSPÖ   ORG    0.988402  \n",
       "32967                                  ÖVP   ORG    0.999398  \n",
       "32968                House of Digitization   ORG    0.986370  \n",
       "\n",
       "[32969 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = pd.read_csv('data/processed_dataset/ambivalent/ner.csv')\n",
    "entities = entities[entities['label'].isin(['PER', 'ORG'])].dropna()\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.HttpClient(host='localhost', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face_key = os.environ['HUGGING_FACE_KEY']\n",
    "embed_function = embedding_functions.HuggingFaceEmbeddingFunction(\n",
    "    api_key=hugging_face_key,\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "collection = client.create_collection(name=\"entities_ambivalent\", embedding_function=embed_function, metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "\n",
    "for _, row in tqdm(entities.iterrows()):\n",
    "    article_id = str(row[\"article_id\"])\n",
    "    name = row[\"name\"]\n",
    "    metadata = {\n",
    "        \"article_id\": article_id,\n",
    "        \"from\": row[\"start_pos\"],\n",
    "        \"to\": row[\"end_pos\"],\n",
    "        \"label\": row[\"label\"],\n",
    "    }\n",
    "\n",
    "    documents.append(name)\n",
    "    metadatas.append(metadata)\n",
    "    ids.append(f\"{article_id}_{row['start_pos']}_{row['end_pos']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(0, len(ids), 1000):\n",
    "    collection.add(\n",
    "        documents=documents[i:i+1000],\n",
    "        metadatas=metadatas[i:i+1000],\n",
    "        ids=ids[i:i+1000]\n",
    "    )\n",
    "    print(f'Added {i} entities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection(\"entities_negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [01:01,  3.47it/s]"
     ]
    }
   ],
   "source": [
    "collection = client.get_collection('entities_ambivalent')\n",
    "sentiments_df = pd.read_csv(\"data/processed_dataset/ambivalent/sentiments.csv\")\n",
    "output = []\n",
    "errors = []\n",
    "for index, row in tqdm(sentiments_df.iterrows()):\n",
    "    try:\n",
    "        article_id = row[\"id\"]\n",
    "        actor = row[\"actor\"]\n",
    "        sentiment = row[\"sentiment\"]\n",
    "        query_result = collection.query(\n",
    "            query_texts=[actor],\n",
    "            n_results=3,\n",
    "            where={\"article_id\": article_id}\n",
    "        )\n",
    "\n",
    "        mentions = []\n",
    "        for entity, metadata, distances in zip(query_result[\"documents\"][0], query_result[\"metadatas\"][0], query_result[\"distances\"][0]):\n",
    "            if distances < 0.32:\n",
    "                mention = {\n",
    "                    \"from\": metadata[\"from\"],\n",
    "                    \"to\": metadata[\"to\"],\n",
    "                    \"mention\": entity\n",
    "                }\n",
    "                mentions.append(mention)\n",
    "\n",
    "        if mentions:\n",
    "            polarity = 0\n",
    "            if sentiment == \"positive\":\n",
    "                polarity = 1\n",
    "            elif sentiment == \"negative\":\n",
    "                polarity = -1\n",
    "            elif sentiment == \"ambivalent\":\n",
    "                polarity = 2\n",
    "\n",
    "            output_item = {\n",
    "                \"id\": article_id,\n",
    "                \"name\": actor,\n",
    "                \"polarity\": polarity,\n",
    "                \"mentions\": mentions\n",
    "            }\n",
    "            output.append(output_item)\n",
    "    except:\n",
    "        errors.append(index)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/processed_dataset/ambivalent/output_ambivalent.txt', 'w', encoding='utf-8') as file:\n",
    "    for item in output:\n",
    "        json_string = json.dumps(item, ensure_ascii=False)\n",
    "        file.write(json_string + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.output_formatter import OutputFormatter\n",
    "output_formatter = OutputFormatter()\n",
    "articles_df = pd.read_csv(\"data/processed_dataset/ambivalent/articles.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.output_formatter import OutputFormatter\n",
    "output_formatter = OutputFormatter()\n",
    "output_path = \"data/processed_dataset/ambivalent/output_ambivalent.txt\"\n",
    "articles_path =\"data/processed_dataset/ambivalent/articles.csv\"\n",
    "# articles_df.columns = ['article_id', 'text_german', 'text_english']\n",
    "d1 = output_formatter.adapt_output_format_for_absa_pytorch(output_path, articles_path)\n",
    "d2 = output_formatter.adapt_output_format_for_newsmtsc(output_path, articles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/processed_dataset/ambivalent/ambivalent_absa_pytorch.jsonl\", \"w\") as f:\n",
    "    for item in d1:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_output_format(output, articles_df):\n",
    "    adapted_output = []\n",
    "    for item in output:\n",
    "        article_id = item[\"id\"]\n",
    "        if articles_df[articles_df[\"article_id\"] == article_id].empty:\n",
    "            continue\n",
    "        sentence_normalized = articles_df.loc[articles_df[\"article_id\"] == article_id, \"text_english\"].values[0]\n",
    "        sorted_mentions = sorted(item['mentions'], key=lambda x: x['from'])\n",
    "        target = {\n",
    "            \"Input.gid\": f\"{article_id}_{mention['from']}_{mention['to']}_{sorted_mentions[0]['mention']}\",\n",
    "            \"from\": mention[\"from\"],\n",
    "            \"to\": mention[\"to\"],\n",
    "            \"mention\": mention[\"mention\"],\n",
    "            \"polarity\": item[\"polarity\"],\n",
    "            \"further_mentions\": [\n",
    "                {\n",
    "                    \"from\": m[\"from\"],\n",
    "                    \"to\": m[\"to\"],\n",
    "                    \"mention\": m[\"mention\"]\n",
    "                }\n",
    "                for i, m in enumerate(sorted_mentions) if i > 0\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        adapted_item = {\n",
    "            \"primary_gid\": f\"{article_id}_{item['mentions'][0]['from']}_{item['mentions'][0]['to']}_{item['mentions'][0]['mention']}\",\n",
    "            \"sentence_normalized\": sentence_normalized,\n",
    "            \"targets\": [target]\n",
    "        }\n",
    "        adapted_output.append(adapted_item)\n",
    "    \n",
    "    return adapted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "articles_df = pd.read_csv(\"data/processed_dataset/negative/articles.csv\", header= None)\n",
    "articles_df.columns = ['article_id', 'text_german', 'text_english']\n",
    "adapted_output = adapt_output_format(output=output, articles_df = articles_df)\n",
    "\n",
    "with open(\"data/processed_dataset/negative/negative.jsonl\", \"w\") as f:\n",
    "    for item in adapted_output:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
